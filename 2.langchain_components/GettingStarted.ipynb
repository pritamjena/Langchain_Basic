{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_openai import ChatOpenAI\n",
    "#llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "#print(llm)\n",
    "\n",
    "from langchain_community.llms import Ollama  # Replace ChatOpenAI with Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"gemma3:4b\",  # Replace with your model name (run `ollama list` to check)\n",
    "    base_url=\"http://localhost:11434\"  # Ollama's default local endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's break down what generative AI is. It's a really hot topic right now, and it’s changing a lot of things. Here's a breakdown in a way that's hopefully easy to understand:\n",
       "\n",
       "**1. What it *is*:**\n",
       "\n",
       "Generative AI refers to a type of artificial intelligence that can **create new content** – text, images, music, code, and more – instead of just analyzing or reacting to existing data. Think of it like a digital artist, writer, or composer, but powered by algorithms.\n",
       "\n",
       "**2. How it Works (Simplified):**\n",
       "\n",
       "* **Training Data:** These AI models are trained on *massive* amounts of data. For example, a text-generating AI like ChatGPT has been trained on billions of words from the internet – books, articles, websites, etc. An image-generating AI like DALL-E 2 has been trained on millions of images and their descriptions.\n",
       "* **Learning Patterns:** During training, the AI learns the patterns, styles, and relationships within that data. It doesn’t “understand” in the same way a human does, but it learns to predict what comes next based on what it’s seen before.\n",
       "* **Generating New Content:** Once trained, you can give the AI a prompt – a question, a request, or a starting point – and it will use its learned patterns to generate something new that fits that prompt.\n",
       "\n",
       "\n",
       "**3. Types of Generative AI:**\n",
       "\n",
       "* **Large Language Models (LLMs):** (Like ChatGPT, Bard, Claude) These generate text – answers to questions, creative writing, summaries, code, etc.\n",
       "* **Image Generators:** (Like DALL-E 2, Midjourney, Stable Diffusion) These create images from text descriptions. You can ask for \"a cat wearing a hat in the style of Van Gogh\" and it will generate an image based on that.\n",
       "* **Music Generators:** (Like Jukebox, Amper) These create original music in various genres.\n",
       "* **Code Generators:** (Like GitHub Copilot) These can write code snippets or even entire programs based on your instructions.\n",
       "* **Video Generators:** (Emerging technology – currently DALL-E 3 and others are working on this) These are starting to generate short video clips.\n",
       "\n",
       "\n",
       "\n",
       "**4. Key Examples:**\n",
       "\n",
       "* **ChatGPT:** Arguably the most well-known, it's a chatbot that can have conversations, write stories, and answer questions.\n",
       "* **DALL-E 2:**  Creates stunning and often surreal images from text.\n",
       "* **Midjourney:** Another popular image generator, known for its artistic and dreamlike outputs.\n",
       "* **Stable Diffusion:** An open-source image generator, giving users more control.\n",
       "\n",
       "**5. Important Notes & Considerations:**\n",
       "\n",
       "* **It’s not truly \"intelligent\":** Generative AI doesn't have consciousness or genuine understanding. It's a sophisticated pattern-matching machine.\n",
       "* **Bias:** Because these models are trained on existing data, they can inherit biases present in that data.\n",
       "* **Copyright and Ownership:** The legal implications of using AI-generated content are still being worked out.\n",
       "\n",
       "---\n",
       "\n",
       "**Resources to Learn More:**\n",
       "\n",
       "* **OpenAI:** [https://openai.com/](https://openai.com/) (The company behind ChatGPT)\n",
       "* **DALL-E 2:** [https://openai.com/dall-e-2/](https://openai.com/dall-e-2/)\n",
       "* **Midjourney:** [https://www.midjourney.com/](https://www.midjourney.com/)\n",
       "* **Stable Diffusion:** [https://stability.ai/](https://stability.ai/)\n",
       "\n",
       "\n",
       "Do you want me to delve deeper into a specific aspect of generative AI, such as:\n",
       "\n",
       "*   How a particular type of generative AI (like image generators) works in more detail?\n",
       "*   The ethical considerations surrounding generative AI?\n",
       "*   Specific examples of how generative AI is being used in different industries?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let’s dive into Langsmith. As an AI Engineer, I can tell you it’s a really exciting and rapidly evolving tool with significant potential for accelerating the development of large language model (LLM) applications. Here’s a breakdown of what you need to know:\n",
       "\n",
       "**What is Langsmith?**\n",
       "\n",
       "Langsmith is a collaborative, open-source platform built by AssemblyAI for data labeling and experimentation with LLMs.  Essentially, it’s designed to dramatically speed up the process of creating high-quality datasets needed to fine-tune and evaluate LLMs.  Traditional data labeling can be incredibly time-consuming, and Langsmith tackles this head-on.\n",
       "\n",
       "**Key Features and How it Works:**\n",
       "\n",
       "* **Collaborative Data Labeling:** This is at the core of Langsmith. It allows multiple people to work on labeling the same data simultaneously, making it much more efficient than individual labeling.\n",
       "* **Web-Based Interface:** No need to install complex software. Langsmith runs entirely in your browser. This accessibility is a huge plus.\n",
       "* **Integration with LLMs:** It's built to work seamlessly with various LLMs like OpenAI's GPT models, Cohere, and others. You can directly query the LLM to help with the labeling process.\n",
       "* **Automated Labeling with LLM Assistance:** Here’s the magic! Langsmith leverages LLMs to *assist* in the labeling process. It does this through prompting techniques:\n",
       "    * **Prompt Templates:** You define templates that guide the LLM in providing labels. For example, you might create a prompt like \"Classify the sentiment of this text as positive, negative, or neutral.\"\n",
       "    * **Chain-of-Thought Prompting:** Langsmith intelligently guides the LLM to explain *how* it arrived at a particular label. This transparency is crucial for understanding the LLM’s reasoning and validating the labels.\n",
       "    * **Active Learning:** Langsmith uses a technique called active learning, where it identifies the data points where the LLM is most uncertain and asks a human to label them. This focuses human effort on the most valuable instances.\n",
       "* **Data Versioning & Tracking:** Langsmith tracks all changes made to your dataset, making it easy to revert to previous versions and understand how labels evolved over time.\n",
       "* **Built-in Reporting & Analytics:** It provides dashboards to visualize the labeling progress, identify biases, and evaluate the performance of your LLM.\n",
       "\n",
       "\n",
       "**Why is Langsmith Important?**\n",
       "\n",
       "* **Reduced Labeling Time:**  The combination of collaborative labeling and LLM assistance drastically reduces the time required to create a labeled dataset.\n",
       "* **Improved Data Quality:** The transparency of the chain-of-thought prompting and the ability to review LLM-generated labels lead to higher quality datasets.\n",
       "* **Faster Experimentation:** It allows you to rapidly iterate on your LLM prompts and datasets.\n",
       "* **Open Source & Community Driven:** Being open source means it’s constantly evolving with community contributions.\n",
       "\n",
       "**Resources to Learn More:**\n",
       "\n",
       "* **Langsmith Website:** [https://www.langsmith.ai/](https://www.langsmith.ai/)\n",
       "* **GitHub Repository:** [https://github.com/assemblyai/langsmith](https://github.com/assemblyai/langsmith)\n",
       "* **Langsmith Documentation:** [https://www.langsmith.ai/docs](https://www.langsmith.ai/docs)\n",
       "\n",
       "\n",
       "\n",
       "**To help me give you even more targeted information, could you tell me:**\n",
       "\n",
       "*   What are you hoping to *do* with Langsmith? (e.g., fine-tuning a specific LLM, building a chatbot, evaluating a model’s performance)\n",
       "*   Are you familiar with any LLMs (e.g., OpenAI’s GPT models, Cohere)?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## chain \n",
    "\n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's dive into Langsmith! As an AI Engineer, I can definitely give you a detailed overview. \n",
       "\n",
       "**Langsmith: The Leading Low-Code LLM Evaluation Platform**\n",
       "\n",
       "Langsmith isn't just another LLM evaluation tool; it's fundamentally changing how we build and improve Large Language Models (LLMs). Here's a breakdown of what makes it significant:\n",
       "\n",
       "**1. Core Concept: Low-Code LLM Evaluation**\n",
       "\n",
       "* **The Problem:** Traditionally, evaluating LLMs is a *highly* manual, time-consuming, and expensive process. It involves creating ground truth datasets, writing complex scripts for evaluation, and painstakingly reviewing outputs. \n",
       "* **Langsmith’s Solution:** Langsmith’s key innovation is *low-code* evaluation. It allows you to quickly and easily set up and run evaluation pipelines *without* needing to be a seasoned Python programmer or a deep expert in LLM development.  It uses a visual interface and pre-built components to streamline the process.\n",
       "\n",
       "**2. Key Features & Components**\n",
       "\n",
       "* **Visual Pipeline Builder:** This is the heart of Langsmith. You drag and drop pre-built components (called \"components\") to create your evaluation workflows.  These components handle various tasks:\n",
       "    * **Prompt Generation:** Automatically generate diverse prompts based on templates, seeds, or even external data.\n",
       "    * **LLM Invocation:** Seamlessly integrates with popular LLMs like OpenAI's GPT models, Anthropic's Claude, Google's Gemini, and more. \n",
       "    * **Human-in-the-Loop (HITL) Evaluation:**  This is *critical*.  Langsmith lets you easily incorporate human annotators to review and label LLM outputs. It manages the workflow, ensures quality, and tracks human effort.\n",
       "    * **Data Annotation:**  Provides tools for annotators to directly label outputs.\n",
       "    * **Metrics Calculation:** Automatically calculates key metrics (precision, recall, F1-score, etc.) based on your ground truth.\n",
       "    * **Data Management:** Integrates with data sources like databases and spreadsheets.\n",
       "* **Templates:** Langsmith provides a vast library of pre-built templates for common LLM evaluation tasks:\n",
       "    * **Fact Verification:** Assess if an LLM’s response is factually accurate.\n",
       "    * **Sentiment Analysis:** Determine the emotional tone of the response.\n",
       "    * **Bias Detection:** Identify potential biases in the LLM's output.\n",
       "    * **Reasoning Evaluation:** Evaluate the LLM's ability to solve problems logically.\n",
       "* **Collaboration Features:** Langsmith supports team collaboration with features like shared workspaces, role-based access control, and audit trails.\n",
       "\n",
       "\n",
       "**3.  Why Langsmith is a Game Changer**\n",
       "\n",
       "* **Speed:**  Reduces evaluation time from weeks or months to days or even hours.\n",
       "* **Cost-Effectiveness:**  Lower evaluation costs due to automation and reduced manual effort.\n",
       "* **Accessibility:**  Democratizes LLM evaluation, allowing teams with varying technical expertise to participate.\n",
       "* **Iterative Improvement:** Facilitates rapid iteration and experimentation, crucial for fine-tuning and improving LLM performance.\n",
       "\n",
       "**4.  Use Cases**\n",
       "\n",
       "* **Fine-tuning LLMs:**  Evaluate and optimize your custom LLMs.\n",
       "* **Prompt Engineering:**  Test and refine prompts to achieve desired outputs.\n",
       "* **Model Comparison:**  Compare the performance of different LLMs.\n",
       "* **Safety & Robustness Testing:**  Assess LLM vulnerabilities and biases.\n",
       "\n",
       "\n",
       "**5. Resources to Learn More**\n",
       "\n",
       "* **Official Website:** [https://www.langsmith.ai/](https://www.langsmith.ai/)\n",
       "* **Documentation:** [https://docs.langsmith.ai/](https://docs.langsmith.ai/)\n",
       "* **Tutorials & Examples:** [https://www.langsmith.ai/tutorials](https://www.langsmith.ai/tutorials)\n",
       "\n",
       "---\n",
       "\n",
       "**To help me give you an even more targeted response, could you tell me:**\n",
       "\n",
       "*   What specifically are you interested in learning about Langsmith? (e.g., its pricing, a particular feature, use case, or comparison with other tools?)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
